{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq8iigYWb2datXghLe4BJ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidfague/Neural-Modeling/blob/main/Function_Group_Simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Full Simulation Run with new modules"
      ],
      "metadata": {
        "id": "dPbgYybZxAK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Dependencies"
      ],
      "metadata": {
        "id": "ciwGs47ixHat"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUb0xOo7w7gt",
        "outputId": "1586a3b5-e892-42eb-9668-e55abd06401f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neuron\n",
            "  Downloading NEURON-8.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.10/dist-packages (from neuron) (1.22.4)\n",
            "Installing collected packages: neuron\n",
            "Successfully installed neuron-8.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install neuron"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neuron_reduce"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cooeav4vxPG5",
        "outputId": "a314cee5-ccc7-4d16-d250-3bf9da3f22ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neuron_reduce\n",
            "  Downloading neuron_reduce-0.0.7-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: neuron_reduce\n",
            "Successfully installed neuron_reduce-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone repo"
      ],
      "metadata": {
        "id": "eRlRASQk_VRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/davidfague/Neural-Modeling.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GOw6xY3xR-W",
        "outputId": "f15272b4-f65c-44b6-8f84-a583b6e067d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Neural-Modeling'...\n",
            "remote: Enumerating objects: 273, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 273 (delta 105), reused 126 (delta 78), pack-reused 109\u001b[K\n",
            "Receiving objects: 100% (273/273), 180.83 KiB | 6.46 MiB/s, done.\n",
            "Resolving deltas: 100% (142/142), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get modules"
      ],
      "metadata": {
        "id": "ynOkYQJz_UNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Neural-Modeling/\n",
        "from Modules.synapse_generator import SynapseGenerator\n",
        "from Modules.Reduction import Reductor\n",
        "from Modules.cell_model import CellModel\n",
        "from Modules.spike_generator import SpikeGenerator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7K-oURLxTiQ",
        "outputId": "62cf03a7-5a0e-4a18-f87e-8e67227e7cd7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Neural-Modeling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# others\n",
        "# import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import scipy.stats as st\n",
        "import random"
      ],
      "metadata": {
        "id": "XKQa6OJmxYQQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build Complex Cell"
      ],
      "metadata": {
        "id": "9SyUE-Vc7Fy_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile modfiles"
      ],
      "metadata": {
        "id": "rgqP23TO90vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nrnivmodl modfiles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s30Jrqug93Kr",
        "outputId": "e16436a1-bdf5-44ed-f4bd-24009bb23a09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Neural-Modeling\n",
            "Mod files: \"modfiles/modfiles/AMPA_NMDA.mod\" \"modfiles/modfiles/AMPA_NMDA_STP_LTP.mod\" \"modfiles/modfiles/AMPA_NMDA_STP.mod\" \"modfiles/modfiles/CaDynamics_E2.mod\" \"modfiles/modfiles/Ca_HVA.mod\" \"modfiles/modfiles/Ca_LVAst.mod\" \"modfiles/modfiles/epsp.mod\" \"modfiles/modfiles/GABA_AB.mod\" \"modfiles/modfiles/GABA_AB_STP.mod\" \"modfiles/modfiles/Ih.mod\" \"modfiles/modfiles/Im.mod\" \"modfiles/modfiles/int2pyr.mod\" \"modfiles/modfiles/K_Pst.mod\" \"modfiles/modfiles/K_Tst.mod\" \"modfiles/modfiles/Nap_Et2.mod\" \"modfiles/modfiles/NaTa_t.mod\" \"modfiles/modfiles/NaTs2_t.mod\" \"modfiles/modfiles/pyr2pyr.mod\" \"modfiles/modfiles/SK_E2.mod\" \"modfiles/modfiles/SKv3_1.mod\" \"modfiles/modfiles/vecevent.mod\"\n",
            "\n",
            "Creating 'x86_64' directory for .o files.\n",
            "\n",
            " -> \u001b[32mCompiling\u001b[0m mod_func.cpp\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/AMPA_NMDA.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/AMPA_NMDA_STP_LTP.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/AMPA_NMDA_STP.mod\n",
            "Translating AMPA_NMDA_STP_LTP.mod into /content/Neural-Modeling/x86_64/AMPA_NMDA_STP_LTP.c\n",
            "Translating AMPA_NMDA_STP.mod into /content/Neural-Modeling/x86_64/AMPA_NMDA_STP.c\n",
            "Translating AMPA_NMDA.mod into /content/Neural-Modeling/x86_64/AMPA_NMDA.c\n",
            "Thread Safe\n",
            "Thread Safe\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/CaDynamics_E2.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/Ca_HVA.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/Ca_LVAst.mod\n",
            "Translating CaDynamics_E2.mod into /content/Neural-Modeling/x86_64/CaDynamics_E2.c\n",
            "Translating Ca_HVA.mod into /content/Neural-Modeling/x86_64/Ca_HVA.c\n",
            "Thread Safe\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/epsp.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/GABA_AB.mod\n",
            "Translating Ca_LVAst.mod into /content/Neural-Modeling/x86_64/Ca_LVAst.c\n",
            "Thread Safe\n",
            "Translating epsp.mod into /content/Neural-Modeling/x86_64/epsp.c\n",
            "Thread Safe\n",
            "Translating GABA_AB.mod into /content/Neural-Modeling/x86_64/GABA_AB.c\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/GABA_AB_STP.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/Ih.mod\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/Im.mod\n",
            "Translating Ih.mod into /content/Neural-Modeling/x86_64/Ih.c\n",
            "Translating GABA_AB_STP.mod into /content/Neural-Modeling/x86_64/GABA_AB_STP.c\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/int2pyr.mod\n",
            "Thread Safe\n",
            "Translating Im.mod into /content/Neural-Modeling/x86_64/Im.c\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/K_Pst.mod\n",
            "Thread Safe\n",
            "Translating int2pyr.mod into /content/Neural-Modeling/x86_64/int2pyr.c\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/K_Tst.mod\n",
            "Translating K_Pst.mod into /content/Neural-Modeling/x86_64/K_Pst.c\n",
            "Thread Safe\n",
            "Translating K_Tst.mod into /content/Neural-Modeling/x86_64/K_Tst.c\n",
            "WARNING: Dimensions may be wrong for READ ica with POINT_PROCESS\n",
            "WARNING: Dimensions may be wrong for READ ica with POINT_PROCESS\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/Nap_Et2.mod\n",
            "Thread Safe\n",
            "WARNING: Dimensions may be wrong for READ ica with POINT_PROCESS\n",
            "WARNING: Dimensions may be wrong for READ ica with POINT_PROCESS\n",
            "WARNING: Dimensions may be wrong for READ ica with POINT_PROCESS\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/NaTs2_t.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/NaTa_t.mod\n",
            "Translating Nap_Et2.mod into /content/Neural-Modeling/x86_64/Nap_Et2.c\n",
            "Translating NaTs2_t.mod into /content/Neural-Modeling/x86_64/NaTs2_t.c\n",
            "Thread Safe\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/pyr2pyr.mod\n",
            "Translating NaTa_t.mod into /content/Neural-Modeling/x86_64/NaTa_t.c\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/SK_E2.mod\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/SKv3_1.mod\n",
            "Translating pyr2pyr.mod into /content/Neural-Modeling/x86_64/pyr2pyr.c\n",
            "Translating SKv3_1.mod into /content/Neural-Modeling/x86_64/SKv3_1.c\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../modfiles/vecevent.mod\n",
            "Translating SK_E2.mod into /content/Neural-Modeling/x86_64/SK_E2.c\n",
            "Thread Safe\n",
            "Translating vecevent.mod into /content/Neural-Modeling/x86_64/vecevent.c\n",
            "Notice: Use of POINTER is not thread safe.\n",
            "Notice: VERBATIM blocks are not thread safe\n",
            "Notice: ARTIFICIAL_CELL is a synonym for POINT_PROCESS which hints that it\n",
            "only affects and is affected by discrete events. As such it is not\n",
            "located in a section and is not associated with an integrator\n",
            "Thread Safe\n",
            " -> \u001b[32mCompiling\u001b[0m AMPA_NMDA.c\n",
            " -> \u001b[32mCompiling\u001b[0m AMPA_NMDA_STP.c\n",
            " -> \u001b[32mCompiling\u001b[0m AMPA_NMDA_STP_LTP.c\n",
            " -> \u001b[32mCompiling\u001b[0m CaDynamics_E2.c\n",
            " -> \u001b[32mCompiling\u001b[0m Ca_HVA.c\n",
            " -> \u001b[32mCompiling\u001b[0m Ca_LVAst.c\n",
            " -> \u001b[32mCompiling\u001b[0m epsp.c\n",
            " -> \u001b[32mCompiling\u001b[0m GABA_AB.c\n",
            " -> \u001b[32mCompiling\u001b[0m GABA_AB_STP.c\n",
            " -> \u001b[32mCompiling\u001b[0m Ih.c\n",
            " -> \u001b[32mCompiling\u001b[0m Im.c\n",
            " -> \u001b[32mCompiling\u001b[0m int2pyr.c\n",
            " -> \u001b[32mCompiling\u001b[0m K_Pst.c\n",
            " -> \u001b[32mCompiling\u001b[0m K_Tst.c\n",
            " -> \u001b[32mCompiling\u001b[0m Nap_Et2.c\n",
            " -> \u001b[32mCompiling\u001b[0m NaTa_t.c\n",
            " -> \u001b[32mCompiling\u001b[0m NaTs2_t.c\n",
            " -> \u001b[32mCompiling\u001b[0m pyr2pyr.c\n",
            " -> \u001b[32mCompiling\u001b[0m SK_E2.c\n",
            " -> \u001b[32mCompiling\u001b[0m SKv3_1.c\n",
            " -> \u001b[32mCompiling\u001b[0m vecevent.c\n",
            " => \u001b[32mLINKING\u001b[0m shared library ./libnrnmech.so\n",
            " => \u001b[32mLINKING\u001b[0m executable ./special LDFLAGS are:    -pthread\n",
            "Successfully created x86_64/special\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from neuron import h\n",
        "h.load_file('stdrun.hoc')\n",
        "h.nrn_load_dll('./x86_64/.libs/libnrnmech.so') # load modfiles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WgZ2TerGEmJ",
        "outputId": "673b9666-df1c-494e-bd34-3c35ef8779d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Complex cell"
      ],
      "metadata": {
        "id": "5xR1869j93lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cell_folder = 'complex_cells/L5PC/'\n",
        "h.load_file(cell_folder+'L5PCbiophys3.hoc') # load biophysics\n",
        "h.load_file(\"import3d.hoc\") # load morphology\n",
        "h.load_file(cell_folder+'L5PCtemplate.hoc') # load builder\n",
        "complex_cell = h.L5PCtemplate(cell_folder+'cell1.asc') # build complex_cell object\n",
        "h.celsius = 37\n",
        "h.v_init = complex_cell.soma[0].e_pas\n",
        "h.tstop = 2000 # sim runtime\n",
        "t = np.arange(0,h.tstop-1,1) # time vector for generating inputs"
      ],
      "metadata": {
        "id": "DY2Dyw3D7GEp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fr_profile = np.zeros((t.shape[0]))\n",
        "print(fr_profile)"
      ],
      "metadata": {
        "id": "eJVZTMAHbA13",
        "outputId": "7cc4c7c7-f7d0-4974-8130-79377e3b98f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optional:\n",
        "optomize complex cell nseg"
      ],
      "metadata": {
        "id": "u3GPbhiXBC6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Reductor(complex_cell, 'lambda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2jZTzkWBIsF",
        "outputId": "ba35d548-8cf6-4779-c67f-f3778771d76b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model nseg changed from 642 to 196\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Modules.Reduction.Reductor at 0x7f2e4b7ea560>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate excitatory synapses and their inputs"
      ],
      "metadata": {
        "id": "-0EmWO0yBBDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FunctionalGroup():\n",
        "  def __init__(self, cell, center_seg, span):\n",
        "    self.center_seg=center_seg\n",
        "    self.segments=[]\n",
        "    self.len_per_segment=[]\n",
        "    self.synapses=[]\n",
        "    self.clusters=[]\n",
        "    for sec in cell.all:\n",
        "      for seg in sec:\n",
        "        if h.distance(center_seg,seg)<span:\n",
        "          self.segments.append(seg)\n",
        "          self.len_per_segment.append(seg.sec.nseg/seg.sec.L)\n",
        "    self.len_per_segment=np.array(self.len_per_segment)\n",
        "\n",
        "class Cluster():\n",
        "  def __init__(self, cell, center_seg, span, functional_group=None):\n",
        "    self.center_seg=center_seg\n",
        "    self.segments=[]\n",
        "    self.len_per_segment=[]\n",
        "    self.synapses=[]\n",
        "    self.clusters=[]\n",
        "    self.spike_trains=[]\n",
        "    self.netcons_list=[]\n",
        "    self.functional_group=functional_group\n",
        "    if functional_group is not None:\n",
        "      self.functional_group.clusters.append(self)\n",
        "    for sec in cell.all:\n",
        "      for seg in sec:\n",
        "        if h.distance(center_seg,seg)<span:\n",
        "          self.segments.append(seg)\n",
        "          self.len_per_segment.append(seg.sec.nseg/seg.sec.L)\n",
        "    self.len_per_segment=np.array(self.len_per_segment)\n",
        "\n",
        "# get all segments\n",
        "all_segments=[]\n",
        "all_len_per_segment=[]\n",
        "for sec in complex_cell.all:\n",
        "  for seg in sec:\n",
        "    all_segments.append(seg)\n",
        "    all_len_per_segment.append(seg.sec.nseg/seg.sec.L)\n",
        "\n",
        "all_len_per_segment=np.array(all_len_per_segment)\n",
        "m=.2\n",
        "s=0.345\n",
        "gmax_mean = np.log(m) - 0.5 * np.log((s/m)**2+1)\n",
        "gmax_std = np.sqrt(np.log((s/m)**2 + 1))\n",
        "gmax_exc_dist = partial(np.random.lognormal, gmax_mean, gmax_std, size=1) # gmax distribution\n",
        "\n",
        "# create functional groups\n",
        "num_groups=52\n",
        "functional_group_span=100\n",
        "functional_groups=[]\n",
        "nodes_per_group=100 # numbet of presynaptic cells\n",
        "cluster_span=10\n",
        "synapses_per_node=5\n",
        "mean_fr_dist=partial(st.levy_stable.rvs, alpha=1.37, beta=-1.00, loc=0.92, scale=0.44, size=1) # distribution of mean firing rates\n",
        "spike_generator=SpikeGenerator()\n",
        "synapse_generator=SynapseGenerator()\n",
        "t=np.arange(0,h.tstop,1)\n",
        "\n",
        "rnd = np.random.RandomState(10)\n",
        "for cluster in range(num_groups): # create functional group\n",
        "  center_seg=rnd.choice(all_segments, p=all_len_per_segment/sum(all_len_per_segment))\n",
        "  func_grp=FunctionalGroup(complex_cell, center_seg, functional_group_span)\n",
        "  functional_groups.append(func_grp)\n",
        "  fr_profile=spike_generator.get_firing_rate_profile(t, mean_firing_rate=mean_fr_dist, method='1f_noise')\n",
        "  for cell in range(nodes_per_group):\n",
        "    cluster_seg=rnd.choice(func_grp.segments, p=func_grp.len_per_segment/sum(func_grp.len_per_segment))\n",
        "    cluster=Cluster(complex_cell, cluster_seg, cluster_span)\n",
        "    cluster.synapses=synapse_generator.add_synapses(segments=cluster.segments,probs=cluster.len_per_segment,gmax=gmax_exc_dist,syn_mod='AMPA_NMDA',number_of_synapses=synapses_per_node)\n",
        "    func_grp.synapses.append(cluster.synapses)\n",
        "    func_grp.clusters.append(cluster)\n",
        "    mean_fr=spike_generator.get_mean_fr(mean_fr_dist)\n",
        "    spikes = spike_generator.generate_spikes_from_profile(fr_profile,mean_fr)\n",
        "    for synapse in cluster.synapses:\n",
        "      print(synapse, synapse.pp_obj)\n",
        "      cluster.netcons_list.append(spike_generator.set_spike_train(synapse, spikes))\n",
        "      cluster.spike_trains.append(spikes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "06AG9jiPv5BR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "ea19ae4c-1f66-4bc6-dce8-97840df0a009"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Modules.synapse.Synapse object at 0x7f2e4b7e8ca0> AMPA_NMDA[0]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7e9030> AMPA_NMDA[1]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7e8fd0> AMPA_NMDA[2]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7e9000> AMPA_NMDA[3]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7e9fc0> AMPA_NMDA[4]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7ebf40> AMPA_NMDA[5]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7ebf10> AMPA_NMDA[6]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7ebee0> AMPA_NMDA[7]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7ebeb0> AMPA_NMDA[8]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7ebe80> AMPA_NMDA[9]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7eb8b0> AMPA_NMDA[10]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7eb880> AMPA_NMDA[11]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7eb850> AMPA_NMDA[12]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7eb820> AMPA_NMDA[13]\n",
            "<Modules.synapse.Synapse object at 0x7f2e4b7eb7f0> AMPA_NMDA[14]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-dda6a20d07c1>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mfunc_grp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mmean_fr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspike_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_fr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_fr_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mspikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspike_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_spikes_from_profile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_profile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_fr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msynapse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynapses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynapse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynapse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpp_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Neural-Modeling/Modules/spike_generator.py\u001b[0m in \u001b[0;36mgenerate_spikes_from_profile\u001b[0;34m(self, fr_profile, mean_fr)\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;34m''' sample spikes '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mfr_profile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr_profile\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmean_fr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0msample_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_profile\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m                 \u001b[0mspike_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_values\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mspike_times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.poisson\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.disc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.discrete_broadcast_d\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_common.pyx\u001b[0m in \u001b[0;36mnumpy.random._common.check_array_constraint\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: lam < 0 or lam contains NaNs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in fr_profile:\n",
        "  print(_)"
      ],
      "metadata": {
        "id": "irhzLOwCCiGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for synapse in cluster.synapses:\n",
        "  print(synapse.pp_obj)"
      ],
      "metadata": {
        "id": "FPMUL1juAO8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SynapseGenerator_exc = SynapseGenerator() # will generate and store new synapses lists"
      ],
      "metadata": {
        "id": "8V7QiEtXOQXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excitatory synapses"
      ],
      "metadata": {
        "id": "M5xxoqvMUIzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # add intracortical and cortico-cortical pyramidal synapses to basal dendrites\n",
        "# segments=[] # list of nrn.segment objects\n",
        "# for sec in complex_cell.dend: # basal only\n",
        "#   for seg in sec:\n",
        "#     segments.append(seg)\n",
        "\n",
        "# len_per_segment = np.array([seg.sec.L/seg.sec.nseg for seg in segments]) # list of random choice probabilities\n",
        "\n",
        "# m=.2\n",
        "# s=0.345\n",
        "# gmax_mean = np.log(m) - 0.5 * np.log((s/m)**2+1)\n",
        "# gmax_std = np.sqrt(np.log((s/m)**2 + 1))\n",
        "# gmax_exc_dist = partial(np.random.lognormal, gmax_mean, gmax_std, size=1) # gmax distribution\n",
        "\n",
        "# intracortical_pyr = SynapseGenerator_exc.add_synapses(segments, gmax=gmax_exc_dist, syn_mod='AMPA_NMDA', density=2.16, probs = len_per_segment, record = False)"
      ],
      "metadata": {
        "id": "ZZEqC8ScBAcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# possibly split synapse list between intracortical and cortico-cortical # cortico-cortical may tend to have stronger weight"
      ],
      "metadata": {
        "id": "-Re5aUw7S3DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # add thalamocortical and cortico-cortical pyramidal synapses to distal apical dendrites\n",
        "# segments=[] # list of nrn.segment objects\n",
        "# for sec in complex_cell.apic: # distal apical only\n",
        "#   if h.distance(complex_cell.soma[0](0.5),sec(0.5))<700:\n",
        "#     for seg in sec:\n",
        "#       segments.append(seg)\n",
        "\n",
        "# len_per_segment = np.array([seg.sec.L/seg.sec.nseg for seg in segments]) # list of random choice probabilities\n",
        "\n",
        "# m=.2\n",
        "# s=0.345\n",
        "# gmax_mean = np.log(m) - 0.5 * np.log((s/m)**2+1)\n",
        "# gmax_std = np.sqrt(np.log((s/m)**2 + 1))\n",
        "# gmax_exc_dist = partial(np.random.lognormal, gmax_mean, gmax_std, size=1) # gmax distribution\n",
        "\n",
        "# thalamocortical_pyr = SynapseGenerator_exc.add_synapses(segments=segments, gmax=gmax_exc_dist, syn_mod='AMPA_NMDA', density=2.16, probs = len_per_segment, record = False)"
      ],
      "metadata": {
        "id": "MQs8QsFgQMQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# possible split synapse list between thalamocortical and cortico-cortical"
      ],
      "metadata": {
        "id": "aHxxMQ_XTPTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excitatory synaptic Inputs"
      ],
      "metadata": {
        "id": "_yh5ghYsVKt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SpikeGenerator_exc = SpikeGenerator() # will generate and store new netcons"
      ],
      "metadata": {
        "id": "fe7XMoeBVKRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# levy_dist = partial(st.levy_stable.rvs, alpha=1.37, beta=-1.00, loc=0.92, scale=0.44, size=1) # distribution of mean firing rates\n",
        "\n",
        "# # intracortical and cortico-cortical pyramidal synapses on basal dendrites\n",
        "# netcons_list, spike_trains = SpikeGenerator_exc.generate_inputs(synapses=intracortical_pyr, t=t, method = '1/f noise', mean_firing_rate=levy_dist) # possibly use same_presynaptic_cell/same_presynaptic_region after splitting lists\n",
        "# # thalamocortical and cortico-cortical pyramidal synapses on distal apical dendrites\n",
        "# netcons_list, spike_trains = SpikeGenerator_exc.generate_inputs(synapses=thalamocortical_pyr, t=t, method = '1/f noise', mean_firing_rate=levy_dist) # possibly use same_presynaptic_cell/same_presynaptic_region after splitting lists)"
      ],
      "metadata": {
        "id": "mvYyqJirVsk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate inhibitory synapses and their inputs"
      ],
      "metadata": {
        "id": "ST65EiLUVDPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inhibitory synapses"
      ],
      "metadata": {
        "id": "ceS8rxvxUKcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SynapseGenerator_inh = SynapseGenerator() # will generate and store new synapses lists"
      ],
      "metadata": {
        "id": "rC7iD9Y4WdYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add proximal intracortical interneuron synapses everywhere at lower density\n",
        "segments=[] # list of nrn.segment objects\n",
        "for sec in complex_cell.all:\n",
        "  if h.distance(complex_cell.soma[0](0.5),sec(0.5))<50: # proximal\n",
        "    for seg in sec:\n",
        "      segments.append(seg)\n",
        "\n",
        "len_per_segment = np.array([seg.sec.L/seg.sec.nseg for seg in segments]) # list of random choice probabilities\n",
        "\n",
        "m=.1\n",
        "s=0.345\n",
        "gmax_mean = np.log(m) - 0.5 * np.log((s/m)**2+1)\n",
        "gmax_std = np.sqrt(np.log((s/m)**2 + 1))\n",
        "gmax_inh_dist = partial(np.random.lognormal, gmax_mean, gmax_std, size=1) # gmax distribution\n",
        "\n",
        "prox_intracortical_int = SynapseGenerator_inh.add_synapses(segments, gmax=gmax_inh_dist, syn_mod='GABA_AB', density=0.22, probs = len_per_segment, record = False)"
      ],
      "metadata": {
        "id": "1m8qgjBYTg2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add distal intracortical interneuron synapses everywhere at lower density\n",
        "segments=[] # list of nrn.segment objects\n",
        "for sec in complex_cell.all:\n",
        "  if h.distance(complex_cell.soma[0](0.5),sec(0.5))>50: # distal\n",
        "    for seg in sec:\n",
        "      segments.append(seg)\n",
        "\n",
        "len_per_segment = np.array([seg.sec.L/seg.sec.nseg for seg in segments]) # list of random choice probabilities\n",
        "\n",
        "m=.1\n",
        "s=0.345\n",
        "gmax_mean = np.log(m) - 0.5 * np.log((s/m)**2+1)\n",
        "gmax_std = np.sqrt(np.log((s/m)**2 + 1))\n",
        "gmax_inh_dist = partial(np.random.lognormal, gmax_mean, gmax_std, size=1) # gmax distribution\n",
        "\n",
        "dist_intracortical_int = SynapseGenerator_inh.add_synapses(segments, gmax=gmax_inh_dist, syn_mod='GABA_AB', density=0.22, probs = len_per_segment, record = False)"
      ],
      "metadata": {
        "id": "oeINND4Sd4rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inhibitroy synaptic Inputs"
      ],
      "metadata": {
        "id": "yTB_a5REUgOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SpikeGenerator_inh = SpikeGenerator() # will generate and store new netcons"
      ],
      "metadata": {
        "id": "YgVwOsvUUwP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# proximal inh mean_fr distribution\n",
        "mean_fr, std_fr = 16.9, 14.3\n",
        "a, b = (0 - mean_fr) / std_fr, (100 - mean_fr) / std_fr\n",
        "proximal_inh_dist = partial(st.truncnorm.rvs, a=a, b=b, loc=mean_fr, scale=std_fr)\n",
        "\n",
        "# intracortical and cortico-cortical pyramidal synapses on basal dendrites\n",
        "netcons_list, spike_trains = SpikeGenerator_inh.generate_inputs(synapses=prox_intracortical_int, t=t, method = 'delay', mean_firing_rate=proximal_inh_dist,) # possibly use same_presynaptic_cell/same_presynaptic_region after splitting lists"
      ],
      "metadata": {
        "id": "WL0bKlSddBfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# distal inh mean_fr distribution\n",
        "mean_fr, std_fr = 3.9, 4.3\n",
        "a, b = (0 - mean_fr) / std_fr, (100 - mean_fr) / std_fr\n",
        "distal_inh_dist = partial(st.truncnorm.rvs, a=a, b=b, loc=mean_fr, scale=std_fr)\n",
        "\n"
      ],
      "metadata": {
        "id": "hd-DCHLgd_bU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}