{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no DISPLAY environment variable.\n",
      "--No graphics will be displayed.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../Modules/\")\n",
    "\n",
    "from Modules.simulation import Simulation\n",
    "from Modules.cell_builder import SkeletonCell, CellBuilder\n",
    "from Modules.constants import HayParameters\n",
    "\n",
    "import os\n",
    "from neuron import h\n",
    "\n",
    "from logger import Logger # type: ignore\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/drfrbc/Neural-Modeling/scripts\n"
     ]
    }
   ],
   "source": [
    "%cd ../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'x86_64/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.system(\"rm -r x86_64/\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_simulations(neuron_random_states, numpy_random_states, varying_attributes, common_attributes):\n",
    "    # Generate the list of HayParameters with updated sim_names\n",
    "    all_parameters = []\n",
    "    \n",
    "    # Define a helper function to create parameters\n",
    "    def create_parameters(numpy_seed, neuron_seed, attributes, amp=None, excFR_increase=None):\n",
    "        sim_name_parts = [attributes['base_sim_name'], f\"Np{numpy_seed}\"]\n",
    "        if neuron_seed is not None:\n",
    "            sim_name_parts.append(f\"Neu{neuron_seed}\")\n",
    "        if amp is not None:\n",
    "            sim_name_parts.append(f\"amp{round(amp, 1)}\")\n",
    "        if excFR_increase is not None:\n",
    "            sim_name_parts.append(f\"EXCinc{round(excFR_increase, 1)}\")\n",
    "        sim_name = '_'.join(sim_name_parts)\n",
    "        \n",
    "        params = {\n",
    "            **common_attributes,\n",
    "            'numpy_random_state': numpy_seed,\n",
    "            'sim_name': sim_name,\n",
    "            **{k: v for k, v in attributes.items() if k != 'base_sim_name'}\n",
    "        }\n",
    "        \n",
    "        if neuron_seed is not None:\n",
    "            params['neuron_random_state'] = neuron_seed\n",
    "        if amp is not None:\n",
    "            params['h_i_amplitude'] = round(amp, 1)\n",
    "        if excFR_increase is not None:\n",
    "            params['excFR_increase'] = round(excFR_increase, 1)\n",
    "            \n",
    "        return HayParameters(**params)\n",
    "    \n",
    "    if not numpy_random_states:\n",
    "        numpy_random_states = [None]\n",
    "    if not neuron_random_states:\n",
    "        neuron_random_states = [None]\n",
    "    \n",
    "    for numpy_seed in numpy_random_states:\n",
    "        for neuron_seed in neuron_random_states:\n",
    "            for attributes in varying_attributes:\n",
    "                if 'CI_on' in common_attributes:\n",
    "                    for amp in np.arange(0, 2.1, 0.5):\n",
    "                        all_parameters.append(create_parameters(numpy_seed, neuron_seed, attributes, amp=amp))\n",
    "                elif 'exc_constant_fr' in common_attributes:\n",
    "                    for excFR_increase in np.arange(0, 8.1, 2):\n",
    "                        all_parameters.append(create_parameters(numpy_seed, neuron_seed, attributes, excFR_increase=excFR_increase))\n",
    "                else:\n",
    "                    all_parameters.append(create_parameters(numpy_seed, neuron_seed, attributes))\n",
    "    \n",
    "    return all_parameters\n",
    "\n",
    "\n",
    "synapse_keys = ['None']#, 'NoMapping'] #'MappingMerging'] #'Mapping', 'Merging', \n",
    "use_SA_probs = True\n",
    "syn_numbers_to_use = 'Full'#'1000'#'Full' # TODO replace with keys\n",
    "common_attributes_to_use = 'sta'#'sta'#'FI_ExcFR' # 'sta' , 'FI' , 'FI_ExcFR' for example\n",
    "morphology_keys = ['Complex']#,'Branches', 'Trees']#['Complex']#['Complex', 'Branches', 'Trees']\n",
    "replace_w_CI_keys = ['None']#, 'Tufts'] #'Basals&Tufts'\n",
    "numpy_random_states = [5]#,10, 1000000]#, 5555555, 88888, 999999, 2222222, 7777777,66666,33333]\n",
    "neuron_random_states = None\n",
    "\n",
    "sim_title = 'TuningSynapses_reduceNA_shiftExcGmaxBy20Percent'#'FINoMapping'#'TuningFRSynapses'#'FSynapses'# if 'sta' in common_attributes_to_use else 'FI'\n",
    "\n",
    "syn_numbers = {\n",
    "    'Density': {'inh': None, 'exc': None},\n",
    "    'Full': {'inh':2650, 'exc':26100},\n",
    "    '1000': {'inh': int(1000 * (2650 / (26100 + 2650))), 'exc': int(1000 * (26100 / (26100 + 2650)))},\n",
    "    '10000': {'inh': int(10000 * (2650 / (26100 + 2650))), 'exc':int(10000 * (26100 / (26100 + 2650)))}\n",
    "}\n",
    "\n",
    "# Define the template for common attributes\n",
    "common_attributes = {\n",
    "    'sta' : \n",
    "        {\n",
    "    'h_tstop': 10000,#120000,\n",
    "    'merge_synapses': False,\n",
    "    'record_ecp': True,\n",
    "    'record_all_channels':True,\n",
    "    'record_all_synapses':True,\n",
    "    'exc_use_density':True if syn_numbers_to_use == 'Density' else False,\n",
    "    'inh_use_density':True if syn_numbers_to_use == 'Density' else False,\n",
    "    'inh_syn_number': syn_numbers[syn_numbers_to_use]['inh'], # 150 soma syns already #2650\n",
    "    'exc_syn_number': syn_numbers[syn_numbers_to_use]['exc'],  # 26100\n",
    "    'use_SA_probs': use_SA_probs\n",
    "    },\n",
    "        \n",
    "    'FI' : \n",
    "        {\n",
    "    'h_tstop': 5000,\n",
    "    'save_every_ms':5000,\n",
    "    'all_synapses_off': False,\n",
    "    'CI_on': True,\n",
    "    'h_i_duration': 4950,\n",
    "    'h_i_delay': 50,\n",
    "    'exc_use_density': True if syn_numbers_to_use == 'Density' else False,\n",
    "    'inh_use_density': True if syn_numbers_to_use == 'Density' else False,\n",
    "    'inh_syn_number': syn_numbers[syn_numbers_to_use]['inh'], # 150 soma syns already #2650\n",
    "    'exc_syn_number': syn_numbers[syn_numbers_to_use]['exc'],  # 26100\n",
    "    'use_SA_probs': use_SA_probs\n",
    "    },\n",
    "    'FI_ExcFR' : # changes exc FR instead of changing CI amp\n",
    "        {\n",
    "    'h_tstop': 5000,\n",
    "    'save_every_ms':5000,\n",
    "    'all_synapses_off': False,\n",
    "    'exc_constant_fr': True,\n",
    "    'h_i_duration': 4950,\n",
    "    'h_i_delay': 50,\n",
    "    'exc_use_density': True if syn_numbers_to_use == 'Density' else False,\n",
    "    'inh_use_density': True if syn_numbers_to_use == 'Density' else False,\n",
    "    'inh_syn_number': syn_numbers[syn_numbers_to_use]['inh'], # 150 soma syns already #2650\n",
    "    'exc_syn_number': syn_numbers[syn_numbers_to_use]['exc'],  # 26100\n",
    "    'use_SA_probs': use_SA_probs\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "morphology_attributes = {\n",
    "    'Complex': {'base_sim_name': 'Complex'},\n",
    "    'Branches': {'base_sim_name': 'Branches', 'reduce_obliques': True, 'reduce_tufts': True, 'reduce_basals': 3},\n",
    "    'Trees': {'base_sim_name': 'Trees', 'reduce_apic': True, 'reduce_basals': 1}\n",
    "}\n",
    "\n",
    "replace_w_CI_attributes = {\n",
    "    'None': {'sim_name_add_suffix': ''},\n",
    "    'Basals': {'sim_name_add_suffix': 'REPBasals', 'num_basal_to_replace_with_CI':8},\n",
    "    '1Basal': {'sim_name_add_suffix': 'REP1Basal', 'num_basal_to_replace_with_CI':1},\n",
    "    'Tufts': {'sim_name_add_suffix': 'REPTufts', 'num_tuft_to_replace_with_CI':2},\n",
    "    '1Tuft': {'sim_name_add_suffix': 'REP1Tuft', 'num_tuft_to_replace_with_CI':1},\n",
    "    'Basals&Tufts': {'sim_name_add_suffix': 'REPBasals&Tufts', 'num_basal_to_replace_with_CI':8, 'num_tuft_to_replace_with_CI':2}\n",
    "}\n",
    "\n",
    "varying_syn_attributes = {\n",
    "    'None': {'sim_name_add_suffix': ''},\n",
    "    'NoMapping': {'sim_name_add_suffix': 'NoMapping', 'synapse_mapping': False},\n",
    "    'Merging': {'sim_name_add_suffix': 'Merging', 'merge_synapses': True},\n",
    "    'MappingMerging': {'sim_name_add_suffix': 'MappingMerging', 'synapse_mapping': True, 'merge_synapses': True}\n",
    "}\n",
    "mean = (np.log(0.45) - 0.5 * np.log((0.35/0.45)**2 + 1))\n",
    "# Add synaptic gmax parameters\n",
    "synaptic_gmax_params = {\n",
    "    'inh_gmax_dist': 2,\n",
    "    'soma_gmax_dist': 2,\n",
    "    'exc_gmax_mean_0': mean - abs(0.2*mean),\n",
    "    'exc_gmax_std_0': np.sqrt(np.log((0.35/0.45)**2 + 1)),\n",
    "    'exc_gmax_clip': (0, 5),\n",
    "    'exc_scalar': 1\n",
    "}\n",
    "\n",
    "conductance_params = {}\n",
    "\n",
    "# Combine common attributes with synaptic gmax parameters\n",
    "common_attributes = {**common_attributes[common_attributes_to_use], **synaptic_gmax_params}\n",
    "\n",
    "# Generate varying attributes by combining morphology, replace_w_CI, and synapse attributes\n",
    "varying_attributes = []\n",
    "for morph_key in morphology_keys:\n",
    "    if (morph_key == 'Complex') or (morph_key == 'Trees'): # Complex cell will not be having any dendrites replaced with Current injection\n",
    "        replace_keys = ['None']\n",
    "    else:\n",
    "        replace_keys = replace_w_CI_keys\n",
    "    for replace_key in replace_keys:\n",
    "        for syn_key in synapse_keys:\n",
    "            combined_attrs = {**morphology_attributes[morph_key], **replace_w_CI_attributes[replace_key], **varying_syn_attributes[syn_key]}\n",
    "            combined_attrs['base_sim_name'] = f\"{morphology_attributes[morph_key]['base_sim_name']}{replace_w_CI_attributes[replace_key].get('sim_name_add_suffix', '')}{varying_syn_attributes[syn_key].get('sim_name_add_suffix', '')}\"\n",
    "            combined_attrs.pop('sim_name_add_prefix', None)\n",
    "            combined_attrs.pop('sim_name_add_suffix', None)\n",
    "            varying_attributes.append(combined_attrs)\n",
    "\n",
    "# Main execution code to generate simulations\n",
    "all_parameters = generate_simulations(neuron_random_states, numpy_random_states, varying_attributes, common_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Complex']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morphology_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parameters = generate_simulations(neuron_random_states, numpy_random_states, varying_attributes, common_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HayParameters(sim_name='Complex_Np5', numpy_random_state=5, neuron_random_state=90, h_celcius=37, h_tstop=30000, h_dt=0.1, h_v_init=-77.2, CI_on=False, CI_target='soma', h_i_amplitude=10.0, h_i_duration=1000, h_i_delay=10, record_ecp=True, record_seg_to_seg=False, all_synapses_off=False, trunk_exc_synapses=True, perisomatic_exc_synapses=True, add_soma_inh_synapses=True, num_soma_inh_syns=450, inh_gmax_dist=2, soma_gmax_dist=2, exc_gmax_mean_0=-1.2420604129312118, exc_gmax_std_0=0.6878119625182042, exc_gmax_clip=(0, 5), exc_scalar=1, exc_synaptic_density=2.16, inh_synaptic_density=0.22, exc_use_density=False, inh_use_density=False, exc_syn_number=26100, inh_syn_number=2650, use_SA_probs=True, exc_P_release_mean=0.53, exc_P_release_std=0.22, inh_basal_P_release_mean=0.72, inh_basal_P_release_std=0.1, inh_apic_P_release_mean=0.3, inh_apic_P_release_std=0.08, inh_soma_P_release_mean=0.88, inh_soma_P_release_std=0.05, exc_syn_mod='AMPA_NMDA_STP', inh_syn_mod='GABA_AB_STP', inh_prox_mean_fr=16.9, inh_prox_std_fr=14.3, inh_distal_mean_fr=3.9, inh_distal_std_fr=4.9, exc_mean_fr=4.43, exc_std_fr=2.9, exc_constant_fr=False, excFR_increase=0.0, exc_n_FuncGroups=50, exc_n_PreCells_per_FuncGroup=100, inh_n_FuncGroups=10, inh_n_PreCells_per_FuncGroup=50, soma_n_fun_gr=1, soma_n_pc_per_fg=150, exc_functional_group_span=100, exc_cluster_span=10, exc_synapses_per_cluster=5, inh_cluster_span=10, inh_number_of_groups=1, inh_functional_group_span=100, soma_number_of_clusters=15, soma_cluster_span=10, soma_synapses_per_cluster=10, soma_number_of_groups=1, soma_functional_group_span=100, spike_threshold=-10, number_of_presynaptic_cells=2651, PSC_start=5, skip=300, save_every_ms=1000, record_every_time_steps=1, path='', reduce_cell=False, expand_cable=False, reduction_frequency=0, choose_branches=22, optimize_nseg_by_lambda=False, merge_synapses=False, segs_per_lambda=10, Hay_biophys='L5PCbiophys3.hoc', build_stylized=False, geometry_file='geom_parameters.csv', only_one_synapse=False, one_syn_index=0, simulate_EPSPs=False, record_soma_spikes=True, record_axon_spikes=False, record_all_channels=True, record_all_synapses=True, record_all_v=True, reduce_cell_NRCE=False, reduce_tufts=False, reduce_apic=False, reduce_basals=0, reduce_obliques=False, synapse_mapping=True, reduce_soma_gpas=False, num_basal_to_replace_with_CI=0, basal_AC_stats=[(0.00693, 0.05926), (-0.0007, 0.05307), (0.01526, 0.09936), (0.00035, 0.0361), (0.00478, 0.17284), (0.01896, 0.07112), (-0.00153, 0.02512), (-0.00151, 0.03715)], num_tuft_to_replace_with_CI=0, tuft_AC_stats=[(0.03897, 0.05233), (0.05814, 0.05911)])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2024-08-13 08:20:38.841692)-[PID: 1606183]–[INFO]: Total number of jobs: 1\n",
      "(2024-08-13 08:20:38.841758)-[PID: 1606183]–[INFO]: Total number of proccessors: 192\n",
      "(2024-08-13 08:20:38.841892)-[PID: 1606183]–[INFO]: Compiling modfiles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'x86_64/': No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2024-08-13 08:20:39.537723)-[PID: 1606495]–[INFO]: Building SkeletonCell.Hay.\n",
      "(2024-08-13 08:20:39.816945)-[PID: 1606495]–[INFO]: CellModel: changed soma nseg from 5 to 1.\n",
      "soma segments:[L5PCtemplate[0].soma[0](0.5)]\n",
      "(2024-08-13 08:20:39.819923)-[PID: 1606495]–[INFO]: Building excitatory synapses.\n",
      "Removing duplicate coordinate at index 1 in section L5PCtemplate[0].apic[0]\n",
      "(2024-08-13 08:22:21.089589)-[PID: 1606495]–[INFO]: Building inhibitory synapses.\n",
      "(2024-08-13 08:22:36.755218)-[PID: 1606495]–[INFO]: Building soma synapses.\n",
      "(2024-08-13 08:22:36.795020)-[PID: 1606495]–[INFO]: Assigning excitatory spike trains.\n"
     ]
    }
   ],
   "source": [
    "# try to run >64 (limit) simulation in batches\n",
    "import math\n",
    "\n",
    "# Define your batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Check how many batches you will need\n",
    "if len(all_parameters) > (batch_size - 1):\n",
    "    number_of_batches = math.ceil(len(all_parameters) / batch_size)\n",
    "    print(number_of_batches)\n",
    "    \n",
    "    # Create batches of indices\n",
    "    batches = [all_parameters[i * batch_size:(i + 1) * batch_size] for i in range(number_of_batches)]\n",
    "    \n",
    "    # Run each batch\n",
    "    for i, batch in enumerate(batches):\n",
    "        sim = Simulation(SkeletonCell.Hay, title=sim_title)\n",
    "        if i == 0:\n",
    "            path_to_use = sim.path\n",
    "        else:\n",
    "            sim.path = path_to_use\n",
    "        for parameters in batch:\n",
    "            sim.submit_job(parameters)\n",
    "        sim.run()\n",
    "        \n",
    "else:\n",
    "    # Initialize simulation\n",
    "    sim = Simulation(SkeletonCell.Hay, title=sim_title)\n",
    "\n",
    "    # Submit jobs to simulation\n",
    "    for parameters in all_parameters:\n",
    "        # print(parameters)\n",
    "        sim.submit_job(parameters)\n",
    "\n",
    "    # Remove directory if it exists\n",
    "    try:\n",
    "        os.system(\"rm -r x86_64/\")\n",
    "    except:    pass\n",
    "\n",
    "    # Run the simulation\n",
    "    sim.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if common_attributes_to_use == 'sta':\n",
    "    import analysis\n",
    "    runtimes = {}\n",
    "\n",
    "    try:\n",
    "        for parameters in all_parameters:\n",
    "            sim_dir = parameters.path\n",
    "            # read parameters\n",
    "            parameters = analysis.DataReader.load_parameters(sim_dir)\n",
    "            # get tstop\n",
    "            tstop = parameters.h_tstop\n",
    "            \n",
    "            # get builder runtime; read parameters.path/build_runtime.txt\n",
    "            build_runtime_path = f\"{sim_dir}/builder_runtime.txt\"\n",
    "            with open(build_runtime_path, 'r') as file:\n",
    "                build_runtime = file.read()\n",
    "\n",
    "            # get simulation runtime; read parameters.path/simulation_runtime.txt\n",
    "            simulation_runtime_path = f\"{sim_dir}/simulation_runtime.txt\"\n",
    "            with open(simulation_runtime_path, 'r') as file:\n",
    "                simulation_runtime = file.read()\n",
    "                \n",
    "            replacement_runtime_path = f\"{sim_dir}/replace_runtime.txt\"\n",
    "            with open(replacement_runtime_path, 'r') as file:\n",
    "                replacement_runtime = file.read()\n",
    "\n",
    "            # Store the runtimes in a dictionary\n",
    "            sim_name = sim_dir.split('/')[-1]  # Get the last part of the path as the simulation name\n",
    "            runtimes[sim_name] = {\n",
    "                'build_time': build_runtime,\n",
    "                'simulation_time': simulation_runtime,\n",
    "                'replacement_time': replacement_runtime\n",
    "            }\n",
    "            \n",
    "        \n",
    "    except:\n",
    "        from scripts.compare_sta import get_all_directories_within\n",
    "        dirs = get_all_directories_within(sim.path)#'05-06-2024-14-19-43-Full120Sec/')\n",
    "        for sim_dir in dirs:\n",
    "                        # read parameters\n",
    "                parameters = analysis.DataReader.load_parameters(sim_dir)\n",
    "                # get tstop\n",
    "                tstop = parameters.h_tstop\n",
    "                \n",
    "                # get builder runtime; read parameters.path/build_runtime.txt\n",
    "                build_runtime_path = f\"{sim_dir}/builder_runtime.txt\"\n",
    "                with open(build_runtime_path, 'r') as file:\n",
    "                    build_runtime = file.read()\n",
    "\n",
    "                # get simulation runtime; read parameters.path/simulation_runtime.txt\n",
    "                simulation_runtime_path = f\"{sim_dir}/simulation_runtime.txt\"\n",
    "                with open(simulation_runtime_path, 'r') as file:\n",
    "                    simulation_runtime = file.read()\n",
    "                    \n",
    "                replacement_runtime_path = f\"{sim_dir}/replace_runtime.txt\"\n",
    "                with open(replacement_runtime_path, 'r') as file:\n",
    "                    replacement_runtime = file.read()\n",
    "\n",
    "                # Store the runtimes in a dictionary\n",
    "                sim_name = sim_dir.split('/')[-1]  # Get the last part of the path as the simulation name\n",
    "                runtimes[sim_name] = {\n",
    "                    'build_time': build_runtime,\n",
    "                    'simulation_time': simulation_runtime,\n",
    "                    'replacement_time': replacement_runtime\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if common_attributes_to_use == 'sta':\n",
    "\n",
    "    # Group runtimes by simulation type\n",
    "    grouped_runtimes = {}\n",
    "\n",
    "    for sim_key, times in runtimes.items():\n",
    "        sim_type = sim_key.split('_')[0]\n",
    "        if sim_type not in grouped_runtimes:\n",
    "            grouped_runtimes[sim_type] = {'build_times': [], 'simulation_times': [], 'replacement_times': []}\n",
    "        \n",
    "        grouped_runtimes[sim_type]['build_times'].append(float(times['build_time'].replace(' seconds', '')))\n",
    "        grouped_runtimes[sim_type]['simulation_times'].append(float(times['simulation_time'].replace(' seconds', '')))\n",
    "        grouped_runtimes[sim_type]['replacement_times'].append(float(times['replacement_time'].replace(' seconds', '')))\n",
    "\n",
    "    # Compute the mean and std of runtimes for each simulation type\n",
    "    summary_stats = {}\n",
    "\n",
    "    for sim_type, times in grouped_runtimes.items():\n",
    "        build_times = times['build_times']\n",
    "        simulation_times = times['simulation_times']\n",
    "        replacement_times = times['replacement_times']\n",
    "\n",
    "        summary_stats[sim_type] = {\n",
    "            'build_time_mean': np.mean(build_times),\n",
    "            'build_time_std': np.std(build_times),\n",
    "            'simulation_time_mean': np.mean(simulation_times),\n",
    "            'simulation_time_std': np.std(simulation_times),\n",
    "            'replacement_time_mean': np.mean(replacement_times),\n",
    "            'replacement_time_std': np.std(replacement_times)\n",
    "        }\n",
    "\n",
    "    # Print the summary statistics\n",
    "    for sim_type, stats in summary_stats.items():\n",
    "        # print(f\"Simulation type: {sim_type}\")\n",
    "        # print(f\"  Build time mean: {stats['build_time_mean']:.2f} seconds\")\n",
    "        # print(f\"  Build time std: {stats['build_time_std']:.2f} seconds\")\n",
    "        # print(f\"  Simulation time mean: {stats['simulation_time_mean']:.2f} seconds\")\n",
    "        # print(f\"  Simulation time std: {stats['simulation_time_std']:.2f} seconds\")\n",
    "        # print(f\"  Replacement time mean: {stats['replacement_time_mean']:.2f} seconds\")\n",
    "        # print(f\"  Replacement time std: {stats['replacement_time_std']:.2f} seconds\")\n",
    "        \n",
    "        # print(f\"                Total time mean : {sum([stats['replacement_time_mean'], stats['simulation_time_mean'], stats['build_time_mean']]):.1f} seconds\")\n",
    "        print(f\"{sim_type} : {sum([stats['replacement_time_mean'], stats['simulation_time_mean'], stats['build_time_mean']]):.1f} (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check LFP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim.path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
