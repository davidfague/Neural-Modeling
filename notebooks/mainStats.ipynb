{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: will need to make adjustments if averaging across seeds or using 1 seed. Starting with one seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../Modules/\")\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import analysis\n",
    "import pyspike as spk\n",
    "\n",
    "%cd ../scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = '/path/to/simulations/'  # Replace with the actual path to your simulation base directory\n",
    "standard_directory = os.path.join(base_directory, 'Complex') # the directory of the main simulation without reduction for calculating errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a stat table. \n",
    "First row: simulation name\n",
    "2. Somatic spike error (1-spike synchrony)\n",
    "3. (sorted table by this ascending): dSpike error (sta R2) ( 1 for each dSpike relationship)\n",
    "4. Runtime ratio = runtime/sim_duration\n",
    "5. number of segments\n",
    "6. nseg_by_lambda (NaN if not optimized by lambda)\n",
    "7-9. Regional Degree of reductions (basal, oblique, tuft)\n",
    "10. Mapping\n",
    "11. LFP Error\n",
    "12. Passive property error\n",
    "13. Build time ratio (buildtime/sim_duration)\n",
    "14. np seed\n",
    "15. neuron seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# simulation_folders = [folder for folder in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, folder))]\n",
    "\n",
    "def get_all_directories_within(directory):\n",
    "    try:\n",
    "        # List all items in the given directory\n",
    "        items = os.listdir(directory)\n",
    "        # Filter out only directories and include the original directory in the path\n",
    "        directories = [os.path.join(directory, item) for item in items if os.path.isdir(os.path.join(base_directory, item))]\n",
    "        return directories\n",
    "    except Exception as e:\n",
    "        raise(e)\n",
    "# consider if these are needed    \n",
    "# grouped_directories = group_directories_by_cell_and_seed(sim_directories)\n",
    "# sta_data, r_squareds, maes, mses = analyze_simulation_directories(grouped_directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# functions for stats\n",
    "\n",
    "# Placeholder function to calculate individual statistics\n",
    "def calculate_somatic_spike_error(standard_simulation: str, simulation_folder: str):\n",
    "    parameters = analysis.DataReader.load_parameters(simulation_folder)\n",
    "    spike_trains = [spk.SpikeTrain(spike_times=analysis.DataReader.read_data(standard_simulation, \"soma_spikes\"), edges = parameters.h_tstop), \n",
    "                spk.SpikeTrain(spike_times=analysis.DataReader.read_data(simulation_folder, \"soma_spikes\"), edges = parameters.h_tstop)]\n",
    "    f = spk.spike_sync_profile(spike_trains[0], spike_trains[1])\n",
    "    return f.avrg()\n",
    "\n",
    "def calculate_dSpike_error(simulation_folder):\n",
    "    # Replace this with actual logic to compute dSpike error (sta R2)\n",
    "    return 0.12  # Example placeholder value\n",
    "\n",
    "def calculate_runtime_ratio(simulation_folder, parameters): \n",
    "    # compute runtime ratio (runtime/sim_duration)\n",
    "    sim_duration = parameters.tstop\n",
    "    # get simulation runtime; read parameters.path/simulation_runtime.txt\n",
    "    simulation_runtime_path = f\"{simulation_folder}/simulation_runtime.txt\" # @MARK make sure that this is total runtime.\n",
    "    with open(simulation_runtime_path, 'r') as file:\n",
    "        sim_runtime = file.read()\n",
    "    runtime_ratio = sim_runtime/sim_duration\n",
    "    return runtime_ratio\n",
    "\n",
    "def calculate_number_of_segments(simulation_folder):\n",
    "    # Replace this with actual logic to compute number of segments\n",
    "    return 100  # Example placeholder value\n",
    "\n",
    "def calculate_nseg_by_lambda(parameters):\n",
    "    # calculate nseg_by_lambda, NaN if not optimized by lambda\n",
    "    if parameters.optimize_nseg_by_lambda:\n",
    "        return parameters.segs_per_lambda\n",
    "    else:\n",
    "        return float('nan')\n",
    "\n",
    "def calculate_regional_reduction(region, parameters):\n",
    "    # Replace this with actual logic to compute regional degree of reductions (basal, oblique, tuft)\n",
    "    if region == 'basal':\n",
    "        return parameters.reduce_basal\n",
    "    elif region == 'oblique':\n",
    "        return parameters.reduce_oblique\n",
    "    elif region == 'tuft':\n",
    "        return parameters.reduce_tufts\n",
    "    elif region == 'apic':\n",
    "        return parameters.reduce_apic\n",
    "\n",
    "def calculate_mapping(parameters):\n",
    "    # compute mapping\n",
    "    return parameters.synapse_mapping\n",
    "\n",
    "def calculate_LFP_error(simulation_folder):\n",
    "    # Replace this with actual logic to compute LFP error\n",
    "    return 0.05  # Example placeholder value\n",
    "\n",
    "def calculate_passive_property_error(simulation_folder):\n",
    "    # Replace this with actual logic to compute passive property error\n",
    "    return 0.1  # Example placeholder value\n",
    "\n",
    "def calculate_build_time_ratio(simulation_folder, parameters):\n",
    "    # compute build time ratio (buildtime/sim_duration)\n",
    "    sim_duration = parameters.tstop\n",
    "    # get simulation runtime; read parameters.path/simulation_runtime.txt\n",
    "    builder_runtime_path = f\"{simulation_folder}/builder_runtime.txt\" # @MARK make sure that this is total runtime.\n",
    "    with open(builder_runtime_path, 'r') as file:\n",
    "        builder_runtime = file.read()\n",
    "    runtime_ratio = builder_runtime/sim_duration\n",
    "    return runtime_ratio\n",
    "\n",
    "# Function to create and fill the statistics table\n",
    "def create_statistics_for_simulations(base_directory):\n",
    "    \"\"\"\n",
    "    Create a table of statistics for each simulation in the base directory.\n",
    "    \n",
    "    Parameters:\n",
    "    base_directory (str): Path to the base directory containing simulation subfolders.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame with calculated statistics for each simulation.\n",
    "    \"\"\"\n",
    "    # Get list of simulation subfolders\n",
    "    simulation_folders = get_all_directories_within(base_directory)\n",
    "\n",
    "    # Initialize a DataFrame to hold the statistics\n",
    "    columns = ['Simulation Name', 'Somatic Spike Error', 'dSpike Error', 'Runtime Ratio', 'Number of Segments',\n",
    "               'nseg_by_lambda', 'Basal Reduction', 'Oblique Reduction', 'Tuft Reduction', 'Mapping', \n",
    "               'LFP Error', 'Passive Property Error', 'Build Time Ratio']\n",
    "    statistics_table = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # Loop over each simulation folder to calculate and add statistics\n",
    "    for simulation in simulation_folders:\n",
    "        simulation_path = os.path.join(base_directory, simulation)\n",
    "        parameters = analysis.DataReader.load_parameters(simulation_path)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        somatic_spike_error = calculate_somatic_spike_error(simulation_path, standard_directory)\n",
    "        dSpike_error = calculate_dSpike_error(simulation_path, standard_directory)\n",
    "        runtime_ratio = calculate_runtime_ratio(simulation_path, parameters)\n",
    "        number_of_segments = calculate_number_of_segments(simulation_path)\n",
    "        nseg_by_lambda = calculate_nseg_by_lambda(parameters)\n",
    "        basal_reduction = calculate_regional_reduction('basal', parameters)\n",
    "        apic_reduction = calculate_regional_reduction('apic', parameters)\n",
    "        oblique_reduction = calculate_regional_reduction('oblique', parameters)\n",
    "        tuft_reduction = calculate_regional_reduction('tuft', parameters)\n",
    "        mapping = calculate_mapping(simulation_path)\n",
    "        LFP_error = calculate_LFP_error(simulation_path, standard_directory)\n",
    "        # passive_property_error = calculate_passive_property_error(simulation_path, standard_directory)\n",
    "        build_time_ratio = calculate_build_time_ratio(simulation_path)\n",
    "\n",
    "        # Add statistics to the table\n",
    "        statistics_table = statistics_table.append({\n",
    "            'Simulation Name': simulation,\n",
    "            'Somatic Spike Error': somatic_spike_error,\n",
    "            'dSpike Error': dSpike_error,\n",
    "            'Runtime Ratio': runtime_ratio,\n",
    "            'Number of Segments': number_of_segments,\n",
    "            'nseg_by_lambda': nseg_by_lambda,\n",
    "            'Basal Reduction': basal_reduction,\n",
    "            'Apic Reduction': apic_reduction,\n",
    "            'Oblique Reduction': oblique_reduction,\n",
    "            'Tuft Reduction': tuft_reduction,\n",
    "            'Mapping': mapping,\n",
    "            'LFP Error': LFP_error,\n",
    "            # 'Passive Property Error': passive_property_error,\n",
    "            'Build Time Ratio': build_time_ratio\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    # Sort the table by dSpike Error (ascending)\n",
    "    statistics_table = statistics_table.sort_values(by='dSpike Error', ascending=True)\n",
    "\n",
    "    return statistics_table\n",
    "\n",
    "# Generate the statistics table for all simulations\n",
    "statistics_table = create_statistics_for_simulations(base_directory)\n",
    "\n",
    "# Display the final statistics table\n",
    "print(statistics_table)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
